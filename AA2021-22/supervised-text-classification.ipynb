{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa5dfab",
   "metadata": {},
   "source": [
    "# Supervised text classification\n",
    "Examples from [https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus](https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98547f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18998045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c9ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/flint/Data/blogtext/blogtext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0529c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918408d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         \n"
     ]
    }
   ],
   "source": [
    "print(data.loc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7934425",
   "metadata": {},
   "source": [
    "## Create some age classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98340d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agek = []\n",
    "for a in data.age.values:\n",
    "    if a < 20:\n",
    "        agek.append(\"< 20\")\n",
    "    elif a < 30:\n",
    "        agek.append(\"20-30\")\n",
    "    else:\n",
    "        agek.append(\"> 30\")\n",
    "data['agek'] = agek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ac04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331aa5b",
   "metadata": {},
   "source": [
    "## Get a dataset sample and show some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.01)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728861bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(var):\n",
    "    g = list(sample.groupby(var).count()['id'].items())\n",
    "    return [x for x, y in g], [y for x, y in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['gender', 'agek', 'topic', 'sign']\n",
    "fig, ax = plt.subplots(figsize=(12, 14), ncols=2, nrows=2)\n",
    "for i, v in enumerate(variables):\n",
    "    ix, iy = i // 2, i % 2\n",
    "    x, y = get_hist(v)\n",
    "    ax[ix, iy].barh(x, y, color='#990000')\n",
    "    ax[ix, iy].set_title(v)\n",
    "    if v == 'topic':\n",
    "        ax[ix, iy].tick_params(axis='y', which='major', labelsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdea7c",
   "metadata": {},
   "source": [
    "## Convert categorical information into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0439e24",
   "metadata": {},
   "source": [
    "### One-hot encoding vs numerical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sample.sign.unique())\n",
    "y_sign = le.transform(sample.sign.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb253a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_sign[:8], [le.classes_[x] for x in y_sign[:8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = preprocessing.OneHotEncoder()\n",
    "oe.fit(sample.sign.unique().reshape(-1, 1))\n",
    "y_sign = oe.transform(sample.sign.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488eb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sign.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48220cdb",
   "metadata": {},
   "source": [
    "## Encoding text\n",
    "- Tokenizers\n",
    "- Pre-processing\n",
    "- Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c29951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [word_tokenize(x.lower()) for x in sample.text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d8cff",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e679f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "W = defaultdict(lambda: 0)\n",
    "run = tqdm(list(enumerate(docs)))\n",
    "for i, doc in run:\n",
    "    wordtf = Counter(doc).most_common()\n",
    "    for word, tf in wordtf:\n",
    "        W[word] += 1\n",
    "        I[i][word] += tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W['love'], I[0]['home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(W.keys())\n",
    "vindex = dict([(w, i) for i, w in enumerate(vocabulary)])\n",
    "X = np.zeros((len(docs), len(vocabulary)))\n",
    "for idoc, words in I.items():\n",
    "    for w, tf in words.items():\n",
    "        X[idoc, vindex[w]] = tf\n",
    "Xf = pd.DataFrame(X, columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf07daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e948749",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = dict([(w, np.log(len(docs) / W[w])) for w in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf['and'], idf['mother']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf.loc[0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8edac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF = pd.Series(idf)\n",
    "Xidf = Xf * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xidf.loc[0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d70b9",
   "metadata": {},
   "source": [
    "## Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(docs, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a772969",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(x)\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline(docs[0])[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36896b3",
   "metadata": {},
   "source": [
    "## Get train dataset for age classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9952ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sample.agek.unique())\n",
    "y_agek = le.transform(sample.agek.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(enumerate(y_agek))\n",
    "np.random.shuffle(labels)\n",
    "limit = int(len(labels) * .8)\n",
    "y_train, y_test = labels[:limit], labels[limit:]\n",
    "train_dataset = [(lab, docs[i]) for i, lab in y_train]\n",
    "test_dataset = [(lab, docs[i]) for i, lab in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a247d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c8c3b",
   "metadata": {},
   "source": [
    "We build a model with the embedding dimension of 64. The vocab size is equal to the length of the vocabulary instance. The number of classes is equal to the number of labels,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(le.classes_)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d6a1d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b503fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2658e7e",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ab1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "total_accu = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21411a",
   "metadata": {},
   "source": [
    "## Comparing train and test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670496f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c22dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "train_pred = []\n",
    "for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
    "    predicted_label = model(text, offsets).argmax(dim=1)\n",
    "    for i, l in enumerate(label):\n",
    "        y_train.append(int(l))\n",
    "        train_pred.append(int(predicted_label[i]))\n",
    "y_test = []\n",
    "test_pred = []\n",
    "for idx, (label, text, offsets) in enumerate(test_dataloader):\n",
    "    predicted_label = model(text, offsets).argmax(dim=1)\n",
    "    for i, l in enumerate(label):\n",
    "        y_test.append(int(l))\n",
    "        test_pred.append(int(predicted_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d691b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b14043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61241060",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1, cm2 = confusion_matrix(y_train, train_pred), confusion_matrix(y_test, test_pred)\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=le.classes_)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7), ncols=2, nrows=1)\n",
    "disp1.plot(ax=ax[0])\n",
    "disp2.plot(ax=ax[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd1e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
